<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.9.2" />
<title>pandas_profiling.model.summary_helpers API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>pandas_profiling.model.summary_helpers</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">import os
import string
from collections import Counter
from datetime import datetime
from functools import partial
from pathlib import Path
from typing import Optional

import numpy as np
import pandas as pd
from scipy.stats.stats import chisquare
from tangled_up_in_unicode import block, block_abbr, category, category_long, script

from pandas_profiling.config import Settings
from pandas_profiling.model.summary_helpers_image import (
    extract_exif,
    hash_image,
    is_image_truncated,
    open_image,
)


def mad(arr: np.ndarray) -&gt; np.ndarray:
    &#34;&#34;&#34;Median Absolute Deviation: a &#34;Robust&#34; version of standard deviation.
    Indices variability of the sample.
    https://en.wikipedia.org/wiki/Median_absolute_deviation
    &#34;&#34;&#34;
    return np.median(np.abs(arr - np.median(arr)))


def named_aggregate_summary(series: pd.Series, key: str) -&gt; dict:
    summary = {
        f&#34;max_{key}&#34;: np.max(series),
        f&#34;mean_{key}&#34;: np.mean(series),
        f&#34;median_{key}&#34;: np.median(series),
        f&#34;min_{key}&#34;: np.min(series),
    }

    return summary


def length_summary(series: pd.Series, summary: dict = None) -&gt; dict:
    if summary is None:
        summary = {}

    length = series.str.len()

    summary.update({&#34;length&#34;: length})
    summary.update(named_aggregate_summary(length, &#34;length&#34;))

    return summary


def file_summary(series: pd.Series) -&gt; dict:
    &#34;&#34;&#34;

    Args:
        series: series to summarize

    Returns:

    &#34;&#34;&#34;

    # Transform
    stats = series.map(lambda x: os.stat(x))

    def convert_datetime(x: float) -&gt; str:
        return datetime.fromtimestamp(x).strftime(&#34;%Y-%m-%d %H:%M:%S&#34;)

    # Transform some more
    summary = {
        &#34;file_size&#34;: stats.map(lambda x: x.st_size),
        &#34;file_created_time&#34;: stats.map(lambda x: x.st_ctime).map(convert_datetime),
        &#34;file_accessed_time&#34;: stats.map(lambda x: x.st_atime).map(convert_datetime),
        &#34;file_modified_time&#34;: stats.map(lambda x: x.st_mtime).map(convert_datetime),
    }
    return summary


def path_summary(series: pd.Series) -&gt; dict:
    &#34;&#34;&#34;

    Args:
        series: series to summarize

    Returns:

    &#34;&#34;&#34;

    # TODO: optimize using value counts
    summary = {
        &#34;common_prefix&#34;: os.path.commonprefix(series.values.tolist())
        or &#34;No common prefix&#34;,
        &#34;stem_counts&#34;: series.map(lambda x: os.path.splitext(x)[0]).value_counts(),
        &#34;suffix_counts&#34;: series.map(lambda x: os.path.splitext(x)[1]).value_counts(),
        &#34;name_counts&#34;: series.map(lambda x: os.path.basename(x)).value_counts(),
        &#34;parent_counts&#34;: series.map(lambda x: os.path.dirname(x)).value_counts(),
        &#34;anchor_counts&#34;: series.map(lambda x: os.path.splitdrive(x)[0]).value_counts(),
    }

    summary[&#34;n_stem_unique&#34;] = len(summary[&#34;stem_counts&#34;])
    summary[&#34;n_suffix_unique&#34;] = len(summary[&#34;suffix_counts&#34;])
    summary[&#34;n_name_unique&#34;] = len(summary[&#34;name_counts&#34;])
    summary[&#34;n_parent_unique&#34;] = len(summary[&#34;parent_counts&#34;])
    summary[&#34;n_anchor_unique&#34;] = len(summary[&#34;anchor_counts&#34;])

    return summary


def url_summary(series: pd.Series) -&gt; dict:
    &#34;&#34;&#34;

    Args:
        series: series to summarize

    Returns:

    &#34;&#34;&#34;
    summary = {
        &#34;scheme_counts&#34;: series.map(lambda x: x.scheme).value_counts(),
        &#34;netloc_counts&#34;: series.map(lambda x: x.netloc).value_counts(),
        &#34;path_counts&#34;: series.map(lambda x: x.path).value_counts(),
        &#34;query_counts&#34;: series.map(lambda x: x.query).value_counts(),
        &#34;fragment_counts&#34;: series.map(lambda x: x.fragment).value_counts(),
    }

    return summary


def count_duplicate_hashes(image_descriptions: dict) -&gt; int:
    &#34;&#34;&#34;

    Args:
        image_descriptions:

    Returns:

    &#34;&#34;&#34;
    counts = pd.Series(
        [x[&#34;hash&#34;] for x in image_descriptions if &#34;hash&#34; in x]
    ).value_counts()
    return counts.sum() - len(counts)


def extract_exif_series(image_exifs: list) -&gt; dict:
    &#34;&#34;&#34;

    Args:
        image_exifs:

    Returns:

    &#34;&#34;&#34;
    exif_keys = []
    exif_values: dict = {}

    for image_exif in image_exifs:
        # Extract key
        exif_keys.extend(list(image_exif.keys()))

        # Extract values per key
        for exif_key, exif_val in image_exif.items():
            if exif_key not in exif_values:
                exif_values[exif_key] = []

            exif_values[exif_key].append(exif_val)

    series = {&#34;exif_keys&#34;: pd.Series(exif_keys, dtype=object).value_counts().to_dict()}

    for k, v in exif_values.items():
        series[k] = pd.Series(v).value_counts()

    return series


def extract_image_information(
    path: Path, exif: bool = False, hash: bool = False
) -&gt; dict:
    &#34;&#34;&#34;Extracts all image information per file, as opening files is slow

    Args:
        path: Path to the image
        exif: extract exif information
        hash: calculate hash (for duplicate detection)

    Returns:
        A dict containing image information
    &#34;&#34;&#34;
    information: dict = {}
    image = open_image(path)
    information[&#34;opened&#34;] = image is not None
    if image is not None:
        information[&#34;truncated&#34;] = is_image_truncated(image)
        if not information[&#34;truncated&#34;]:
            information[&#34;size&#34;] = image.size
            if exif:
                information[&#34;exif&#34;] = extract_exif(image)
            if hash:
                information[&#34;hash&#34;] = hash_image(image)

    return information


def image_summary(series: pd.Series, exif: bool = False, hash: bool = False) -&gt; dict:
    &#34;&#34;&#34;

    Args:
        series: series to summarize
        exif: extract exif information
        hash: calculate hash (for duplicate detection)

    Returns:

    &#34;&#34;&#34;

    image_information = series.apply(
        partial(extract_image_information, exif=exif, hash=hash)
    )
    summary = {
        &#34;n_truncated&#34;: sum(
            [1 for x in image_information if &#34;truncated&#34; in x and x[&#34;truncated&#34;]]
        ),
        &#34;image_dimensions&#34;: pd.Series(
            [x[&#34;size&#34;] for x in image_information if &#34;size&#34; in x],
            name=&#34;image_dimensions&#34;,
        ),
    }

    image_widths = summary[&#34;image_dimensions&#34;].map(lambda x: x[0])
    summary.update(named_aggregate_summary(image_widths, &#34;width&#34;))
    image_heights = summary[&#34;image_dimensions&#34;].map(lambda x: x[1])
    summary.update(named_aggregate_summary(image_heights, &#34;height&#34;))
    image_areas = image_widths * image_heights
    summary.update(named_aggregate_summary(image_areas, &#34;area&#34;))

    if hash:
        summary[&#34;n_duplicate_hash&#34;] = count_duplicate_hashes(image_information)

    if exif:
        exif_series = extract_exif_series(
            [x[&#34;exif&#34;] for x in image_information if &#34;exif&#34; in x]
        )
        summary[&#34;exif_keys_counts&#34;] = exif_series[&#34;exif_keys&#34;]
        summary[&#34;exif_data&#34;] = exif_series

    return summary


def get_character_counts(series: pd.Series) -&gt; Counter:
    &#34;&#34;&#34;Function to return the character counts

    Args:
        series: the Series to process

    Returns:
        A dict with character counts
    &#34;&#34;&#34;
    return Counter(series.str.cat())


def counter_to_series(counter: Counter) -&gt; pd.Series:
    if not counter:
        return pd.Series([], dtype=object)

    counter_as_tuples = counter.most_common()
    items, counts = zip(*counter_as_tuples)
    return pd.Series(counts, index=items)


def unicode_summary(series: pd.Series) -&gt; dict:
    # Unicode Character Summaries (category and script name)
    character_counts = get_character_counts(series)

    character_counts_series = counter_to_series(character_counts)

    char_to_block = {key: block(key) for key in character_counts.keys()}
    char_to_category_short = {key: category(key) for key in character_counts.keys()}
    char_to_script = {key: script(key) for key in character_counts.keys()}

    summary = {
        &#34;n_characters&#34;: len(character_counts_series),
        &#34;character_counts&#34;: character_counts_series,
        &#34;category_alias_values&#34;: {
            key: category_long(value) for key, value in char_to_category_short.items()
        },
        &#34;block_alias_values&#34;: {
            key: block_abbr(value) for key, value in char_to_block.items()
        },
    }
    # Retrieve original distribution
    block_alias_counts: Counter = Counter()
    per_block_char_counts: dict = {
        k: Counter() for k in summary[&#34;block_alias_values&#34;].values()
    }
    for char, n_char in character_counts.items():
        block_name = summary[&#34;block_alias_values&#34;][char]
        block_alias_counts[block_name] += n_char
        per_block_char_counts[block_name][char] = n_char
    summary[&#34;block_alias_counts&#34;] = counter_to_series(block_alias_counts)
    summary[&#34;block_alias_char_counts&#34;] = {
        k: counter_to_series(v) for k, v in per_block_char_counts.items()
    }

    script_counts: Counter = Counter()
    per_script_char_counts: dict = {k: Counter() for k in char_to_script.values()}
    for char, n_char in character_counts.items():
        script_name = char_to_script[char]
        script_counts[script_name] += n_char
        per_script_char_counts[script_name][char] = n_char
    summary[&#34;script_counts&#34;] = counter_to_series(script_counts)
    summary[&#34;script_char_counts&#34;] = {
        k: counter_to_series(v) for k, v in per_script_char_counts.items()
    }

    category_alias_counts: Counter = Counter()
    per_category_alias_char_counts: dict = {
        k: Counter() for k in summary[&#34;category_alias_values&#34;].values()
    }
    for char, n_char in character_counts.items():
        category_alias_name = summary[&#34;category_alias_values&#34;][char]
        category_alias_counts[category_alias_name] += n_char
        per_category_alias_char_counts[category_alias_name][char] += n_char
    summary[&#34;category_alias_counts&#34;] = counter_to_series(category_alias_counts)
    summary[&#34;category_alias_char_counts&#34;] = {
        k: counter_to_series(v) for k, v in per_category_alias_char_counts.items()
    }

    # Unique counts
    summary[&#34;n_category&#34;] = len(summary[&#34;category_alias_counts&#34;])
    summary[&#34;n_scripts&#34;] = len(summary[&#34;script_counts&#34;])
    summary[&#34;n_block_alias&#34;] = len(summary[&#34;block_alias_counts&#34;])
    if len(summary[&#34;category_alias_counts&#34;]) &gt; 0:
        summary[&#34;category_alias_counts&#34;].index = summary[
            &#34;category_alias_counts&#34;
        ].index.str.replace(&#34;_&#34;, &#34; &#34;)

    return summary


def histogram_compute(
    config: Settings,
    finite_values: np.ndarray,
    n_unique: int,
    name: str = &#34;histogram&#34;,
    weights: Optional[np.ndarray] = None,
) -&gt; dict:
    stats = {}
    bins = config.plot.histogram.bins
    bins_arg = &#34;auto&#34; if bins == 0 else min(bins, n_unique)
    stats[name] = np.histogram(finite_values, bins=bins_arg, weights=weights)

    max_bins = config.plot.histogram.max_bins
    if bins_arg == &#34;auto&#34; and len(stats[name][1]) &gt; max_bins:
        stats[name] = np.histogram(finite_values, bins=max_bins, weights=None)

    return stats


def chi_square(
    values: Optional[np.ndarray] = None, histogram: Optional[np.ndarray] = None
) -&gt; dict:
    if histogram is None:
        histogram, _ = np.histogram(values, bins=&#34;auto&#34;)
    return dict(chisquare(histogram)._asdict())


def word_summary(series: pd.Series) -&gt; dict:
    # TODO: preprocess (stopwords)
    # TODO: configurable lowercase/punctuation etc.
    word_lists = series.str.lower().str.split()
    words = word_lists.explode()
    words = words.str.strip(string.punctuation)
    return {&#34;word_counts&#34;: words.value_counts()}</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="pandas_profiling.model.summary_helpers.chi_square"><code class="name flex">
<span>def <span class="ident">chi_square</span></span>(<span>values: Union[numpy.ndarray, NoneType] = None, histogram: Union[numpy.ndarray, NoneType] = None) ‑> dict</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def chi_square(
    values: Optional[np.ndarray] = None, histogram: Optional[np.ndarray] = None
) -&gt; dict:
    if histogram is None:
        histogram, _ = np.histogram(values, bins=&#34;auto&#34;)
    return dict(chisquare(histogram)._asdict())</code></pre>
</details>
</dd>
<dt id="pandas_profiling.model.summary_helpers.count_duplicate_hashes"><code class="name flex">
<span>def <span class="ident">count_duplicate_hashes</span></span>(<span>image_descriptions: dict) ‑> int</span>
</code></dt>
<dd>
<div class="desc"><h2 id="args">Args</h2>
<p>image_descriptions:
Returns:</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def count_duplicate_hashes(image_descriptions: dict) -&gt; int:
    &#34;&#34;&#34;

    Args:
        image_descriptions:

    Returns:

    &#34;&#34;&#34;
    counts = pd.Series(
        [x[&#34;hash&#34;] for x in image_descriptions if &#34;hash&#34; in x]
    ).value_counts()
    return counts.sum() - len(counts)</code></pre>
</details>
</dd>
<dt id="pandas_profiling.model.summary_helpers.counter_to_series"><code class="name flex">
<span>def <span class="ident">counter_to_series</span></span>(<span>counter: collections.Counter) ‑> pandas.core.series.Series</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def counter_to_series(counter: Counter) -&gt; pd.Series:
    if not counter:
        return pd.Series([], dtype=object)

    counter_as_tuples = counter.most_common()
    items, counts = zip(*counter_as_tuples)
    return pd.Series(counts, index=items)</code></pre>
</details>
</dd>
<dt id="pandas_profiling.model.summary_helpers.extract_exif_series"><code class="name flex">
<span>def <span class="ident">extract_exif_series</span></span>(<span>image_exifs: list) ‑> dict</span>
</code></dt>
<dd>
<div class="desc"><h2 id="args">Args</h2>
<p>image_exifs:
Returns:</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def extract_exif_series(image_exifs: list) -&gt; dict:
    &#34;&#34;&#34;

    Args:
        image_exifs:

    Returns:

    &#34;&#34;&#34;
    exif_keys = []
    exif_values: dict = {}

    for image_exif in image_exifs:
        # Extract key
        exif_keys.extend(list(image_exif.keys()))

        # Extract values per key
        for exif_key, exif_val in image_exif.items():
            if exif_key not in exif_values:
                exif_values[exif_key] = []

            exif_values[exif_key].append(exif_val)

    series = {&#34;exif_keys&#34;: pd.Series(exif_keys, dtype=object).value_counts().to_dict()}

    for k, v in exif_values.items():
        series[k] = pd.Series(v).value_counts()

    return series</code></pre>
</details>
</dd>
<dt id="pandas_profiling.model.summary_helpers.extract_image_information"><code class="name flex">
<span>def <span class="ident">extract_image_information</span></span>(<span>path: pathlib.Path, exif: bool = False, hash: bool = False) ‑> dict</span>
</code></dt>
<dd>
<div class="desc"><p>Extracts all image information per file, as opening files is slow</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>path</code></strong></dt>
<dd>Path to the image</dd>
<dt><strong><code>exif</code></strong></dt>
<dd>extract exif information</dd>
<dt><strong><code>hash</code></strong></dt>
<dd>calculate hash (for duplicate detection)</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>A dict containing image information</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def extract_image_information(
    path: Path, exif: bool = False, hash: bool = False
) -&gt; dict:
    &#34;&#34;&#34;Extracts all image information per file, as opening files is slow

    Args:
        path: Path to the image
        exif: extract exif information
        hash: calculate hash (for duplicate detection)

    Returns:
        A dict containing image information
    &#34;&#34;&#34;
    information: dict = {}
    image = open_image(path)
    information[&#34;opened&#34;] = image is not None
    if image is not None:
        information[&#34;truncated&#34;] = is_image_truncated(image)
        if not information[&#34;truncated&#34;]:
            information[&#34;size&#34;] = image.size
            if exif:
                information[&#34;exif&#34;] = extract_exif(image)
            if hash:
                information[&#34;hash&#34;] = hash_image(image)

    return information</code></pre>
</details>
</dd>
<dt id="pandas_profiling.model.summary_helpers.file_summary"><code class="name flex">
<span>def <span class="ident">file_summary</span></span>(<span>series: pandas.core.series.Series) ‑> dict</span>
</code></dt>
<dd>
<div class="desc"><h2 id="args">Args</h2>
<dl>
<dt><strong><code>series</code></strong></dt>
<dd>series to summarize</dd>
</dl>
<p>Returns:</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def file_summary(series: pd.Series) -&gt; dict:
    &#34;&#34;&#34;

    Args:
        series: series to summarize

    Returns:

    &#34;&#34;&#34;

    # Transform
    stats = series.map(lambda x: os.stat(x))

    def convert_datetime(x: float) -&gt; str:
        return datetime.fromtimestamp(x).strftime(&#34;%Y-%m-%d %H:%M:%S&#34;)

    # Transform some more
    summary = {
        &#34;file_size&#34;: stats.map(lambda x: x.st_size),
        &#34;file_created_time&#34;: stats.map(lambda x: x.st_ctime).map(convert_datetime),
        &#34;file_accessed_time&#34;: stats.map(lambda x: x.st_atime).map(convert_datetime),
        &#34;file_modified_time&#34;: stats.map(lambda x: x.st_mtime).map(convert_datetime),
    }
    return summary</code></pre>
</details>
</dd>
<dt id="pandas_profiling.model.summary_helpers.get_character_counts"><code class="name flex">
<span>def <span class="ident">get_character_counts</span></span>(<span>series: pandas.core.series.Series) ‑> collections.Counter</span>
</code></dt>
<dd>
<div class="desc"><p>Function to return the character counts</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>series</code></strong></dt>
<dd>the Series to process</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>A dict with character counts</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_character_counts(series: pd.Series) -&gt; Counter:
    &#34;&#34;&#34;Function to return the character counts

    Args:
        series: the Series to process

    Returns:
        A dict with character counts
    &#34;&#34;&#34;
    return Counter(series.str.cat())</code></pre>
</details>
</dd>
<dt id="pandas_profiling.model.summary_helpers.histogram_compute"><code class="name flex">
<span>def <span class="ident">histogram_compute</span></span>(<span>config: <a title="pandas_profiling.config.Settings" href="../config.html#pandas_profiling.config.Settings">Settings</a>, finite_values: numpy.ndarray, n_unique: int, name: str = 'histogram', weights: Union[numpy.ndarray, NoneType] = None) ‑> dict</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def histogram_compute(
    config: Settings,
    finite_values: np.ndarray,
    n_unique: int,
    name: str = &#34;histogram&#34;,
    weights: Optional[np.ndarray] = None,
) -&gt; dict:
    stats = {}
    bins = config.plot.histogram.bins
    bins_arg = &#34;auto&#34; if bins == 0 else min(bins, n_unique)
    stats[name] = np.histogram(finite_values, bins=bins_arg, weights=weights)

    max_bins = config.plot.histogram.max_bins
    if bins_arg == &#34;auto&#34; and len(stats[name][1]) &gt; max_bins:
        stats[name] = np.histogram(finite_values, bins=max_bins, weights=None)

    return stats</code></pre>
</details>
</dd>
<dt id="pandas_profiling.model.summary_helpers.image_summary"><code class="name flex">
<span>def <span class="ident">image_summary</span></span>(<span>series: pandas.core.series.Series, exif: bool = False, hash: bool = False) ‑> dict</span>
</code></dt>
<dd>
<div class="desc"><h2 id="args">Args</h2>
<dl>
<dt><strong><code>series</code></strong></dt>
<dd>series to summarize</dd>
<dt><strong><code>exif</code></strong></dt>
<dd>extract exif information</dd>
<dt><strong><code>hash</code></strong></dt>
<dd>calculate hash (for duplicate detection)</dd>
</dl>
<p>Returns:</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def image_summary(series: pd.Series, exif: bool = False, hash: bool = False) -&gt; dict:
    &#34;&#34;&#34;

    Args:
        series: series to summarize
        exif: extract exif information
        hash: calculate hash (for duplicate detection)

    Returns:

    &#34;&#34;&#34;

    image_information = series.apply(
        partial(extract_image_information, exif=exif, hash=hash)
    )
    summary = {
        &#34;n_truncated&#34;: sum(
            [1 for x in image_information if &#34;truncated&#34; in x and x[&#34;truncated&#34;]]
        ),
        &#34;image_dimensions&#34;: pd.Series(
            [x[&#34;size&#34;] for x in image_information if &#34;size&#34; in x],
            name=&#34;image_dimensions&#34;,
        ),
    }

    image_widths = summary[&#34;image_dimensions&#34;].map(lambda x: x[0])
    summary.update(named_aggregate_summary(image_widths, &#34;width&#34;))
    image_heights = summary[&#34;image_dimensions&#34;].map(lambda x: x[1])
    summary.update(named_aggregate_summary(image_heights, &#34;height&#34;))
    image_areas = image_widths * image_heights
    summary.update(named_aggregate_summary(image_areas, &#34;area&#34;))

    if hash:
        summary[&#34;n_duplicate_hash&#34;] = count_duplicate_hashes(image_information)

    if exif:
        exif_series = extract_exif_series(
            [x[&#34;exif&#34;] for x in image_information if &#34;exif&#34; in x]
        )
        summary[&#34;exif_keys_counts&#34;] = exif_series[&#34;exif_keys&#34;]
        summary[&#34;exif_data&#34;] = exif_series

    return summary</code></pre>
</details>
</dd>
<dt id="pandas_profiling.model.summary_helpers.length_summary"><code class="name flex">
<span>def <span class="ident">length_summary</span></span>(<span>series: pandas.core.series.Series, summary: dict = None) ‑> dict</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def length_summary(series: pd.Series, summary: dict = None) -&gt; dict:
    if summary is None:
        summary = {}

    length = series.str.len()

    summary.update({&#34;length&#34;: length})
    summary.update(named_aggregate_summary(length, &#34;length&#34;))

    return summary</code></pre>
</details>
</dd>
<dt id="pandas_profiling.model.summary_helpers.mad"><code class="name flex">
<span>def <span class="ident">mad</span></span>(<span>arr: numpy.ndarray) ‑> numpy.ndarray</span>
</code></dt>
<dd>
<div class="desc"><p>Median Absolute Deviation: a "Robust" version of standard deviation.
Indices variability of the sample.
<a href="https://en.wikipedia.org/wiki/Median_absolute_deviation">https://en.wikipedia.org/wiki/Median_absolute_deviation</a></p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def mad(arr: np.ndarray) -&gt; np.ndarray:
    &#34;&#34;&#34;Median Absolute Deviation: a &#34;Robust&#34; version of standard deviation.
    Indices variability of the sample.
    https://en.wikipedia.org/wiki/Median_absolute_deviation
    &#34;&#34;&#34;
    return np.median(np.abs(arr - np.median(arr)))</code></pre>
</details>
</dd>
<dt id="pandas_profiling.model.summary_helpers.named_aggregate_summary"><code class="name flex">
<span>def <span class="ident">named_aggregate_summary</span></span>(<span>series: pandas.core.series.Series, key: str) ‑> dict</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def named_aggregate_summary(series: pd.Series, key: str) -&gt; dict:
    summary = {
        f&#34;max_{key}&#34;: np.max(series),
        f&#34;mean_{key}&#34;: np.mean(series),
        f&#34;median_{key}&#34;: np.median(series),
        f&#34;min_{key}&#34;: np.min(series),
    }

    return summary</code></pre>
</details>
</dd>
<dt id="pandas_profiling.model.summary_helpers.path_summary"><code class="name flex">
<span>def <span class="ident">path_summary</span></span>(<span>series: pandas.core.series.Series) ‑> dict</span>
</code></dt>
<dd>
<div class="desc"><h2 id="args">Args</h2>
<dl>
<dt><strong><code>series</code></strong></dt>
<dd>series to summarize</dd>
</dl>
<p>Returns:</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def path_summary(series: pd.Series) -&gt; dict:
    &#34;&#34;&#34;

    Args:
        series: series to summarize

    Returns:

    &#34;&#34;&#34;

    # TODO: optimize using value counts
    summary = {
        &#34;common_prefix&#34;: os.path.commonprefix(series.values.tolist())
        or &#34;No common prefix&#34;,
        &#34;stem_counts&#34;: series.map(lambda x: os.path.splitext(x)[0]).value_counts(),
        &#34;suffix_counts&#34;: series.map(lambda x: os.path.splitext(x)[1]).value_counts(),
        &#34;name_counts&#34;: series.map(lambda x: os.path.basename(x)).value_counts(),
        &#34;parent_counts&#34;: series.map(lambda x: os.path.dirname(x)).value_counts(),
        &#34;anchor_counts&#34;: series.map(lambda x: os.path.splitdrive(x)[0]).value_counts(),
    }

    summary[&#34;n_stem_unique&#34;] = len(summary[&#34;stem_counts&#34;])
    summary[&#34;n_suffix_unique&#34;] = len(summary[&#34;suffix_counts&#34;])
    summary[&#34;n_name_unique&#34;] = len(summary[&#34;name_counts&#34;])
    summary[&#34;n_parent_unique&#34;] = len(summary[&#34;parent_counts&#34;])
    summary[&#34;n_anchor_unique&#34;] = len(summary[&#34;anchor_counts&#34;])

    return summary</code></pre>
</details>
</dd>
<dt id="pandas_profiling.model.summary_helpers.unicode_summary"><code class="name flex">
<span>def <span class="ident">unicode_summary</span></span>(<span>series: pandas.core.series.Series) ‑> dict</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def unicode_summary(series: pd.Series) -&gt; dict:
    # Unicode Character Summaries (category and script name)
    character_counts = get_character_counts(series)

    character_counts_series = counter_to_series(character_counts)

    char_to_block = {key: block(key) for key in character_counts.keys()}
    char_to_category_short = {key: category(key) for key in character_counts.keys()}
    char_to_script = {key: script(key) for key in character_counts.keys()}

    summary = {
        &#34;n_characters&#34;: len(character_counts_series),
        &#34;character_counts&#34;: character_counts_series,
        &#34;category_alias_values&#34;: {
            key: category_long(value) for key, value in char_to_category_short.items()
        },
        &#34;block_alias_values&#34;: {
            key: block_abbr(value) for key, value in char_to_block.items()
        },
    }
    # Retrieve original distribution
    block_alias_counts: Counter = Counter()
    per_block_char_counts: dict = {
        k: Counter() for k in summary[&#34;block_alias_values&#34;].values()
    }
    for char, n_char in character_counts.items():
        block_name = summary[&#34;block_alias_values&#34;][char]
        block_alias_counts[block_name] += n_char
        per_block_char_counts[block_name][char] = n_char
    summary[&#34;block_alias_counts&#34;] = counter_to_series(block_alias_counts)
    summary[&#34;block_alias_char_counts&#34;] = {
        k: counter_to_series(v) for k, v in per_block_char_counts.items()
    }

    script_counts: Counter = Counter()
    per_script_char_counts: dict = {k: Counter() for k in char_to_script.values()}
    for char, n_char in character_counts.items():
        script_name = char_to_script[char]
        script_counts[script_name] += n_char
        per_script_char_counts[script_name][char] = n_char
    summary[&#34;script_counts&#34;] = counter_to_series(script_counts)
    summary[&#34;script_char_counts&#34;] = {
        k: counter_to_series(v) for k, v in per_script_char_counts.items()
    }

    category_alias_counts: Counter = Counter()
    per_category_alias_char_counts: dict = {
        k: Counter() for k in summary[&#34;category_alias_values&#34;].values()
    }
    for char, n_char in character_counts.items():
        category_alias_name = summary[&#34;category_alias_values&#34;][char]
        category_alias_counts[category_alias_name] += n_char
        per_category_alias_char_counts[category_alias_name][char] += n_char
    summary[&#34;category_alias_counts&#34;] = counter_to_series(category_alias_counts)
    summary[&#34;category_alias_char_counts&#34;] = {
        k: counter_to_series(v) for k, v in per_category_alias_char_counts.items()
    }

    # Unique counts
    summary[&#34;n_category&#34;] = len(summary[&#34;category_alias_counts&#34;])
    summary[&#34;n_scripts&#34;] = len(summary[&#34;script_counts&#34;])
    summary[&#34;n_block_alias&#34;] = len(summary[&#34;block_alias_counts&#34;])
    if len(summary[&#34;category_alias_counts&#34;]) &gt; 0:
        summary[&#34;category_alias_counts&#34;].index = summary[
            &#34;category_alias_counts&#34;
        ].index.str.replace(&#34;_&#34;, &#34; &#34;)

    return summary</code></pre>
</details>
</dd>
<dt id="pandas_profiling.model.summary_helpers.url_summary"><code class="name flex">
<span>def <span class="ident">url_summary</span></span>(<span>series: pandas.core.series.Series) ‑> dict</span>
</code></dt>
<dd>
<div class="desc"><h2 id="args">Args</h2>
<dl>
<dt><strong><code>series</code></strong></dt>
<dd>series to summarize</dd>
</dl>
<p>Returns:</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def url_summary(series: pd.Series) -&gt; dict:
    &#34;&#34;&#34;

    Args:
        series: series to summarize

    Returns:

    &#34;&#34;&#34;
    summary = {
        &#34;scheme_counts&#34;: series.map(lambda x: x.scheme).value_counts(),
        &#34;netloc_counts&#34;: series.map(lambda x: x.netloc).value_counts(),
        &#34;path_counts&#34;: series.map(lambda x: x.path).value_counts(),
        &#34;query_counts&#34;: series.map(lambda x: x.query).value_counts(),
        &#34;fragment_counts&#34;: series.map(lambda x: x.fragment).value_counts(),
    }

    return summary</code></pre>
</details>
</dd>
<dt id="pandas_profiling.model.summary_helpers.word_summary"><code class="name flex">
<span>def <span class="ident">word_summary</span></span>(<span>series: pandas.core.series.Series) ‑> dict</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def word_summary(series: pd.Series) -&gt; dict:
    # TODO: preprocess (stopwords)
    # TODO: configurable lowercase/punctuation etc.
    word_lists = series.str.lower().str.split()
    words = word_lists.explode()
    words = words.str.strip(string.punctuation)
    return {&#34;word_counts&#34;: words.value_counts()}</code></pre>
</details>
</dd>
</dl>
</section>
<section>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="pandas_profiling.model" href="index.html">pandas_profiling.model</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="pandas_profiling.model.summary_helpers.chi_square" href="#pandas_profiling.model.summary_helpers.chi_square">chi_square</a></code></li>
<li><code><a title="pandas_profiling.model.summary_helpers.count_duplicate_hashes" href="#pandas_profiling.model.summary_helpers.count_duplicate_hashes">count_duplicate_hashes</a></code></li>
<li><code><a title="pandas_profiling.model.summary_helpers.counter_to_series" href="#pandas_profiling.model.summary_helpers.counter_to_series">counter_to_series</a></code></li>
<li><code><a title="pandas_profiling.model.summary_helpers.extract_exif_series" href="#pandas_profiling.model.summary_helpers.extract_exif_series">extract_exif_series</a></code></li>
<li><code><a title="pandas_profiling.model.summary_helpers.extract_image_information" href="#pandas_profiling.model.summary_helpers.extract_image_information">extract_image_information</a></code></li>
<li><code><a title="pandas_profiling.model.summary_helpers.file_summary" href="#pandas_profiling.model.summary_helpers.file_summary">file_summary</a></code></li>
<li><code><a title="pandas_profiling.model.summary_helpers.get_character_counts" href="#pandas_profiling.model.summary_helpers.get_character_counts">get_character_counts</a></code></li>
<li><code><a title="pandas_profiling.model.summary_helpers.histogram_compute" href="#pandas_profiling.model.summary_helpers.histogram_compute">histogram_compute</a></code></li>
<li><code><a title="pandas_profiling.model.summary_helpers.image_summary" href="#pandas_profiling.model.summary_helpers.image_summary">image_summary</a></code></li>
<li><code><a title="pandas_profiling.model.summary_helpers.length_summary" href="#pandas_profiling.model.summary_helpers.length_summary">length_summary</a></code></li>
<li><code><a title="pandas_profiling.model.summary_helpers.mad" href="#pandas_profiling.model.summary_helpers.mad">mad</a></code></li>
<li><code><a title="pandas_profiling.model.summary_helpers.named_aggregate_summary" href="#pandas_profiling.model.summary_helpers.named_aggregate_summary">named_aggregate_summary</a></code></li>
<li><code><a title="pandas_profiling.model.summary_helpers.path_summary" href="#pandas_profiling.model.summary_helpers.path_summary">path_summary</a></code></li>
<li><code><a title="pandas_profiling.model.summary_helpers.unicode_summary" href="#pandas_profiling.model.summary_helpers.unicode_summary">unicode_summary</a></code></li>
<li><code><a title="pandas_profiling.model.summary_helpers.url_summary" href="#pandas_profiling.model.summary_helpers.url_summary">url_summary</a></code></li>
<li><code><a title="pandas_profiling.model.summary_helpers.word_summary" href="#pandas_profiling.model.summary_helpers.word_summary">word_summary</a></code></li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.9.2</a>.</p>
</footer>
</body>
</html>